{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build RAG pipeline using Open Source Large Languages\n",
        "\n",
        "In the notebook we will build a Chat with Website use cases using Zephyr 7B model"
      ],
      "metadata": {
        "id": "J177jX51J1Li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "Syag3oIcKHM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L18fYAOPJzZX"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import RAG components required to build pipeline"
      ],
      "metadata": {
        "id": "4FopYAa6Krjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.vectorstores import FAISS, Chroma\n",
        "from langchain.chains import RetrievalQA, LLMChain"
      ],
      "metadata": {
        "id": "kGXeRCdILsha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup HuggingFace Access Token\n",
        "\n",
        "- Log in to [HuggingFace.co](https://huggingface.co/)\n",
        "- Click on your profile icon at the top-right corner, then choose [‚ÄúSettings.‚Äù](https://huggingface.co/settings/)\n",
        "- In the left sidebar, navigate to [‚ÄúAccess Token‚Äù](https://huggingface.co/settings/tokens)\n",
        "- Generate a new access token, assigning it the ‚Äúwrite‚Äù role.\n"
      ],
      "metadata": {
        "id": "DmzD-oWKLtOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "HF_TOKEN = getpass(\"HF Token:\")\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEfA-vDcKrI5",
        "outputId": "cb0beb18-e837-42fa-8b38-73a30d7b80bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF Token:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## External data/document - ETL"
      ],
      "metadata": {
        "id": "KFyNhHmsMYBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ziRBTGT3NF7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEBSITE_URL = \"https://tarunjain.netlify.app/\""
      ],
      "metadata": {
        "id": "h7QVgNPmLkKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(WEBSITE_URL)\n",
        "loader.requests_per_second = 1\n",
        "docs = loader.aload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOrnY8dgMdxt",
        "outputId": "8396674b-0060-4657-a3c8-f1656569d6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00, 15.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "K1TTrH5QNQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitting - Chunking"
      ],
      "metadata": {
        "id": "Z_A2nX3-Ptgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=20)\n",
        "chunks = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "Bouw0M5ANVqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsc6K_Z3NnhT",
        "outputId": "620a215d-4d2f-4794-f041-b5f1fe611172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"Tarun Jain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nAbout Me\\nEvents\\nAchievements\\nProjects\\nWork\\nConnect\\n\\nResume\\n\\n\\nAI with Tarun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIt's Me...  Tarun Jain\\n\\n DevRel @AI Planetü•ë ||  Community Lead @Embedchain.aiü§ó||  GDE in MLüöÄ \\nKnow more\", metadata={'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain', 'language': 'pt-BR'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jenEDd6hN7Cn",
        "outputId": "d3a20482-47c5-4ebc-c9c3-d2fff7bb3c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='About Me', metadata={'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain', 'language': 'pt-BR'})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLh3j6guOTLY",
        "outputId": "5e322c13-e7df-4778-d21d-b970bbb2084d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"Hello! My name is Tarun R Jain. I'm a passionate coder with expertise in Machine Learning, Image Processing, and Deep Learning. I've published over 80 blog articles documenting my coding journey, and I'm actively involved in various\", metadata={'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain', 'language': 'pt-BR'})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-lh4cUSO5EH",
        "outputId": "4687d140-34dc-424c-f876-812def6616e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='involved in various communities, including Hugging Face-Keras Working Group, Deep Learning AI- Bangalore Ambassador, TensorFlow User Group Bangalore- Assistant Organizer and Geeksforgeeks- Technical content writer.', metadata={'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain', 'language': 'pt-BR'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZw3iXPPlGs",
        "outputId": "9c062fb2-9407-4a43-a6a8-c0632adc712d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"What I love most about coding is the ability to create something new and solve complex problems. I'm constantly learning and experimenting with new techniques to improve my skills and knowledge. In addition to my technical pursuits, I also\", metadata={'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain', 'language': 'pt-BR'})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "wxL78Mn0P3N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=HF_TOKEN, model_name=\"BAAI/bge-base-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "QcUdFP8cPz1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Store - FAISS or ChromaDB"
      ],
      "metadata": {
        "id": "cJMgeAOrQfuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "_rMc5YphQiFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmJth21AQx8V",
        "outputId": "cdf4101a-0e78-4356-8636-2b61253c6f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7c4a34463a00>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Where does Tarun work?\"\n",
        "search = vectorstore.similarity_search(query)"
      ],
      "metadata": {
        "id": "MxUNoeFeR7-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "45HgM9wsSCKH",
        "outputId": "69e29351-7374-43c0-d0c0-7001ddfb637f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Tarun Jain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nAbout Me\\nEvents\\nAchievements\\nProjects\\nWork\\nConnect\\n\\nResume\\n\\n\\nAI with Tarun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIt's Me...  Tarun Jain\\n\\n DevRel @AI Planetü•ë ||  Community Lead @Embedchain.aiü§ó||  GDE in MLüöÄ \\nKnow more\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever"
      ],
      "metadata": {
        "id": "4mVaIlkZRiXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\", #similarity\n",
        "    search_kwargs={'k': 4}\n",
        ")"
      ],
      "metadata": {
        "id": "rK67OkSQRbnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC4Xly8XSf26",
        "outputId": "a5e65a81-a093-4c76-ab8b-dc3ff17e61b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Tarun Jain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\nAbout Me\\nEvents\\nAchievements\\nProjects\\nWork\\nConnect\\n\\nResume\\n\\n\\nAI with Tarun\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIt's Me...  Tarun Jain\\n\\n DevRel @AI Planetü•ë ||  Community Lead @Embedchain.aiü§ó||  GDE in MLüöÄ \\nKnow more\", metadata={'language': 'pt-BR', 'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain'}),\n",
              " Document(page_content='MangaPi\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHyperspectral Image Compression Using MATLAB (Hardware)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppreciate my Work\\nFeel free to check this resources...\\n\\n\\n\\n\\n\\n\\nAI With Tarun:\\nSubscribe...', metadata={'language': 'pt-BR', 'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain'}),\n",
              " Document(page_content='MediaPipe Tasks API Bootcamp\\n\\r\\n                 I explained the need for Mediapipe and its applications. And later the participants implemented Mediapipe Tasks projects in the Audio, Image and Text domains.', metadata={'language': 'pt-BR', 'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain'}),\n",
              " Document(page_content='pursuits, I also enjoy watching anime and reading manga in my free time.', metadata={'language': 'pt-BR', 'source': 'https://tarunjain.netlify.app/', 'title': 'Tarun Jain'})]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Large Language Model - Open Source"
      ],
      "metadata": {
        "id": "al9E1TqMS7Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"huggingfaceh4/zephyr-7b-alpha\",\n",
        "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64,\"max_new_tokens\":512}\n",
        ")"
      ],
      "metadata": {
        "id": "MKDFEMDSS9ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template and User Input (Augment - Step 2)"
      ],
      "metadata": {
        "id": "_dy-nCxqTQTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Name the projects Tarun has worked on?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        " <|system|>\n",
        "You are an AI assistant that follows instruction extremely well.\n",
        "Please be truthful and give direct answers\n",
        "</s>\n",
        " <|user|>\n",
        " {query}\n",
        " </s>\n",
        " <|assistant|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C_pCkm2jTHtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG RetrievalQA chain"
      ],
      "metadata": {
        "id": "5Y2ukOe5TS6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever)"
      ],
      "metadata": {
        "id": "aUEmwLYvTWG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa.run(prompt)"
      ],
      "metadata": {
        "id": "sVN8b7LIUMHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "6rQCeRzTUnQ2",
        "outputId": "64cd59bc-d02f-425b-b948-84c2b13311a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nIn addition to MangaPi, a hardware-based hyperspectral image compression project using MATLAB, Tarun has worked on a variety of other projects. One such project was a computer vision project that involved developing a face recognition system using OpenCV. Additionally, Tarun participated in an Object Tracking Bootcamp, where he worked on a vehicle tracking project. \\n\\nTarun's experience in these projects, as well as his participation in hackathons and competitions, demonstrates his passion for innovation and problem-solving in the fields of computer vision, machine learning, and artificial intelligence.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain"
      ],
      "metadata": {
        "id": "eOm3anhXTwg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "M4dKOO7QUTa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        " <|system|>\n",
        "You are an AI assistant that follows instruction extremely well.\n",
        "Please be truthful and give direct answers\n",
        "</s>\n",
        " <|user|>\n",
        " {query}\n",
        " </s>\n",
        " <|assistant|>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aBDfjug4U61T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "oGSLkCc7U8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "hLfDSrrzU1kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"Name the projects Tarun has worked on?\")"
      ],
      "metadata": {
        "id": "35B_JEcKVERB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyor1d0xVHnW",
        "outputId": "506da551-aaa2-409b-88fc-466e2a65b216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not have access to specific information about any particular person unless it is publicly available. however, if you provide me with the name \"tarun\" and specify which tarun you are referring to, i can help you with that. please provide me with more context or details.\n"
          ]
        }
      ]
    }
  ]
}